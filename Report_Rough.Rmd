---
title: "STA 585 Report Rough Draft"
author: "Andrew Deighan"
date: "April 17, 2017"
output: html_document
---

# Methods and Results

## Yearly Insured Rates

```{r, include=F, eval=FALSE}

library(RSocrata)
url_base <- "https://chronicdata.cdc.gov/resource/fn2i-3j6c.json?"

Insured.Rates.11 <- read.socrata(paste0(url_base,
                                        "question=Do you have any kind of health care coverage?",
                                        "&year=2011",
                                        "&break_out=Overall",
                                        "&response=Yes")
                                 )

Insured.Rates.11 <- Insured.Rates.11[, c("locationabbr", "confidence_limit_low", "data_value", "confidence_limit_high", "sample_size")]
colnames(Insured.Rates.11) <- c("State", "CI.LB", "Estimate", "CI.UB", "Sample.Size")
write.csv(Insured.Rates.11, "data/2011 Insured Rates.csv")

Insured.Rates.12 <- read.socrata(paste0(url_base,
                                        "question=Do you have any kind of health care coverage?",
                                        "&year=2012",
                                        "&break_out=Overall",
                                        "&response=Yes")
)

Insured.Rates.12 <- Insured.Rates.12[, c("locationabbr", "confidence_limit_low", "data_value", "confidence_limit_high", "sample_size")]
colnames(Insured.Rates.12) <- c("State", "CI.LB", "Estimate", "CI.UB", "Sample.Size")
write.csv(Insured.Rates.12, "data/2012 Insured Rates.csv")

Insured.Rates.13 <- read.socrata(paste0(url_base,
                                        "question=Do you have any kind of health care coverage?",
                                        "&year=2013",
                                        "&break_out=Overall",
                                        "&response=Yes")
)

Insured.Rates.13 <- Insured.Rates.13[, c("locationabbr", "confidence_limit_low", "data_value", "confidence_limit_high", "sample_size")]
colnames(Insured.Rates.13) <- c("State", "CI.LB", "Estimate", "CI.UB", "Sample.Size")
write.csv(Insured.Rates.13, "data/2013 Insured Rates.csv")

Insured.Rates.14 <- read.socrata(paste0(url_base,
                                        "question=Do you have any kind of health care coverage?",
                                        "&year=2014",
                                        "&break_out=Overall",
                                        "&response=Yes")
)

Insured.Rates.14 <- Insured.Rates.14[, c("locationabbr", "confidence_limit_low", "data_value", "confidence_limit_high", "sample_size")]
colnames(Insured.Rates.14) <- c("State", "CI.LB", "Estimate", "CI.UB", "Sample.Size")
write.csv(Insured.Rates.14, "data/2014 Insured Rates.csv")

Insured.Rates.15 <- read.socrata(paste0(url_base,
                                        "question=Do you have any kind of health care coverage?",
                                        "&year=2015",
                                        "&break_out=Overall",
                                        "&response=Yes")
)

Insured.Rates.15 <- Insured.Rates.15[, c("locationabbr", "confidence_limit_low", "data_value", "confidence_limit_high", "sample_size")]
colnames(Insured.Rates.15) <- c("State", "CI.LB", "Estimate", "CI.UB", "Sample.Size")
write.csv(Insured.Rates.15, "data/2015 Insured Rates.csv")

```

```{r, include=F}

Insured.Rates.11 <- read.csv("data/2011 Insured Rates.csv")[,2:6]
Insured.Rates.12 <- read.csv("data/2012 Insured Rates.csv")[,2:6]
Insured.Rates.13 <- read.csv("data/2013 Insured Rates.csv")[,2:6]
Insured.Rates.14 <- read.csv("data/2014 Insured Rates.csv")[,2:6]
Insured.Rates.15 <- read.csv("data/2015 Insured Rates.csv")[,2:6]

National.IR_calc <- function(x, alpha = 0.05){
  
  z <- qnorm(alpha/2, lower.tail = F)
  n <- sum(x[1:53,5])
  
  IR <- sum(x[1:53,3]*x[1:53,5])/ (n)
  SE <- sqrt(sum(x[1:53,5]*x[1:53,3]*(100 - x[1:53,3]))) / (n)
  LB <- IR - z*SE
  UB <- IR + z*SE
  
  out <- c(round(LB, digits = 4), round(IR, digits = 4), round(UB, digits = 4), round(SE, digits = 4))
  
  out
}

MedicaidExp.IR_calc <- function(x, alpha = 0.05){
  df <- x[1:53,]
  df <- df[order(df$State),]
  df <- df[df$State != "AK" 
          & df$State != "AR" 
          & df$State != "AZ" 
          & df$State != "IA" 
          & df$State != "IN" 
          & df$State != "MI"
          & df$State != "NH" 
          & df$State != "PA"
          & df$State != "WI",]
  
  mdf <- df[df$State != "AL" 
          & df$State != "FL" 
          & df$State != "GA" 
          & df$State != "ID" 
          & df$State != "KS" 
          & df$State != "LA"
          & df$State != "ME" 
          & df$State != "MS"
          & df$State != "MT"
          & df$State != "MO" 
          & df$State != "NE" 
          & df$State != "NC" 
          & df$State != "OK" 
          & df$State != "SC"
          & df$State != "SD" 
          & df$State != "TN"
          & df$State != "TX"
          & df$State != "UT" 
          & df$State != "VA"
          & df$State != "WY",]
  
  nmdf <- df[df$State == "AL" 
          | df$State == "FL" 
          | df$State == "GA" 
          | df$State == "ID" 
          | df$State == "KS" 
          | df$State == "LA"
          | df$State == "ME" 
          | df$State == "MS"
          | df$State == "MT"
          | df$State == "MO" 
          | df$State == "NE" 
          | df$State == "NC" 
          | df$State == "OK" 
          | df$State == "SC"
          | df$State == "SD" 
          | df$State == "TN"
          | df$State == "TX"
          | df$State == "UT" 
          | df$State == "VA"
          | df$State == "WY",]
  
  z <- qnorm(alpha/2, lower.tail = F)
  
  n <- sum(mdf[,5])
  IR <- sum(mdf[,3]*mdf[,5])/ (n)
  SE <- sqrt(sum(mdf[,5]*mdf[,3]*(100 - mdf[,3]))) / (n)
  LB <- IR - z*SE
  UB <- IR + z*SE
  
  out <- c(round(LB, digits = 4), round(IR, digits = 4), round(UB, digits = 4), round(SE, digits = 4))
  
  n <- sum(nmdf[,5])
  IR <- sum(nmdf[,3]*nmdf[,5])/ (n)
  SE <- sqrt(sum(nmdf[,5]*nmdf[,3]*(100 - nmdf[,3]))) / (n)
  LB <- IR - z*SE
  UB <- IR + z*SE
  
  out <- c(out, round(LB, digits = 4), round(IR, digits = 4), round(UB, digits = 4), round(SE, digits = 4))
  
  out

}

Yearly.IR <- matrix(c(National.IR_calc(Insured.Rates.11), MedicaidExp.IR_calc(Insured.Rates.11),
                      National.IR_calc(Insured.Rates.12), MedicaidExp.IR_calc(Insured.Rates.12),
                      National.IR_calc(Insured.Rates.13), MedicaidExp.IR_calc(Insured.Rates.13),
                      National.IR_calc(Insured.Rates.14), MedicaidExp.IR_calc(Insured.Rates.14),
                      National.IR_calc(Insured.Rates.15), MedicaidExp.IR_calc(Insured.Rates.15)),
                     nrow = 15, ncol = 4, byrow = T,
                     dimnames = list(c("2011", "2001", "2011", 
                                       "2012", "2012", "2012", 
                                       "2013", "2013", "2013", 
                                       "2014", "2014", "2014", 
                                       "2015", "2015", "2015"), 
                                     c("Lower Bound", "Estimate", "Upper Bound", "Standard Error"))
                     )

```

  Tables 1, 2 and 3 report the estimated yearly insured rates of adults for the nation as a whole, states that adopted medicaid expansion on January 1st 2014, and those states that had not adopted the expansion as of the end of 2015. These insured rates were estimated from the 2011 to 2015 BRFSS which is restricted to adults. This restriction may account for the estimated insured rates reported here being slightly less than those reported by the US Census Bureau. The percentage of insured adults does indeed rise from 2011 to 2015, even in states that did not adopt the Medicaid expansion. Moreover, there appears to be a particularly sharp increase from 2013 to 2015, which corresponds temporally with the initiation of most of the ACA reforms. However, states that did not adopt the Medicaid expansion had lower insured rates than those that did. Figures 1 and 2 show this graphically.

***

```{r, echo=F, results="asis"}

library(pander)

x <- Yearly.IR[c(1,4,7,10,13),]

pandoc.table(x, caption = "**Table 1:** Estimated yearly adult insured rates (in percentages) for the nation as a whole. The table gives 95% confidence intervals for the percentage of insured adults as estimated from the 2011 to 2015 BRFSS surveys.", split.table = Inf)

```

<br>

```{r, echo=F, results="asis"}

x <- Yearly.IR[c(2,5,8,11,14),]

pandoc.table(x, caption = "**Table 2:** Estimated yearly adult insured rates (in percentages) for states that adopted the Medicaid expansion on January 1st 2014. The table gives 95% confidence intervals for the percentage of insured adults in states that adopted the Medicaid expansion, as estimated from the 2011 to 2015 BRFSS surveys.", split.table = Inf)

```

<br>

```{r, echo=F, results="asis"}

x <- Yearly.IR[c(3,6,9,12,15),]

pandoc.table(x, caption = "**Table 3:** Estimated yearly adult insured rates (in percentages) for states that had not adopted the Medicaid expansion as of the end of 2015. The table gives 95% confidence intervals for the percentage of insured adults in states that did not adopt the Medicaid expansion, as estimated from the 2011 to 2015 BRFSS surveys.", split.table = Inf)

rm(x)

```

<br>

```{r, include=F}

png("plots/Nation_IR.png",
     height = 400, width = 480)
 
barcenters <- barplot(Yearly.IR[c(1,4,7,10,13),2], 
                      ylim = c( 80  , 92 ),
                      main = "Estimated Insured Rates among Adults: National Level", 
                      ylab = "Percentage",
                      xpd = FALSE, cex.names = .9, cex.main = 1 )

abline(h=80)

segments(barcenters, Yearly.IR[c(1,4,7,10,13),1], barcenters,Yearly.IR[c(1,4,7,10,13),3], 
         lwd = 1.5)

arrows(barcenters, Yearly.IR[c(1,4,7,10,13),1], barcenters, Yearly.IR[c(1,4,7,10,13),3], 
       lwd = 1.5, angle = 90, code = 3, length = 0.05)

dev.off()


```

![**Figure 1:** The plot above shows the estimated percentage of insured adults from 2011 to 2105. The line segments at the top of each bar represent the estimated 95% confidence intervals for the percentage of insured adults. Note the jump in percentage from 2013 to 2014.](plots/Nation_IR.png)

<br>

```{r, include=F}

png("plots/Medicaid_IR.png",
     height = 400, width = 800)

par(mfrow=c(1,2))
barplot(Yearly.IR[c(2,5,8,11,14),2], 
        ylim = c( 80,92 ),
        main = NA,
        sub = "Medicaid Expansion", 
        ylab = "Percentage",
        xpd = FALSE, 
        cex.names = .9, cex.main = 1
        )
abline(h=80)

segments(barcenters, Yearly.IR[c(2,5,8,11,14),1], barcenters, Yearly.IR[c(2,5,8,11,14),3], 
         lwd = 1.5)

arrows(barcenters, Yearly.IR[c(2,5,8,11,14),1], barcenters, Yearly.IR[c(2,5,8,11,14),3], 
       lwd = 1.5, angle = 90, code = 3, length = 0.05)

barplot(Yearly.IR[c(3,6,9,12,15),2], 
        ylim = c(80, 92),
        main = NA,
        sub = "No Medicaid Expansion", 
        ylab = NA,
        xpd = FALSE, 
        cex.names = .9, cex.main = 1
        )
abline(h=80)

segments(barcenters, Yearly.IR[c(3,6,9,12,15),1], barcenters, Yearly.IR[c(3,6,9,12,15),3], 
         lwd = 1.5)

arrows(barcenters, Yearly.IR[c(3,6,9,12,15),1], barcenters, Yearly.IR[c(3,6,9,12,15),3], 
       lwd = 1.5, angle = 90, code = 3, length = 0.05)

mtext('Estimated Insured Rates among Adults: States with Medicaid Expansion and States without', outer = TRUE, font = 2, padj = 2)

dev.off()

```

![**Figure 2:** The plots above show the estimated percentage of adults with insurance in states that adopted the Medicaid expansion at the beginning of 2014 and those that had not adopted the expansion as of the end of 2015. The line segments at the top of each bar indicate the 95% confidence for the percentage of insured adults for that year. It is clear that in both states with and without the Medicaid expansion, insured rates have increased from 2011 to 2015 and there was a sharp boost in insured rates from 2013 to 2014 that corresponds with the initiation of most of the ACA reforms. Also, it is clear that while insured rates increaed for both Medicaid expansion states and non-Medicaid expansion states, overall the percentage of insured adults in states without the expansion is much lower..](plots/Medicaid_IR.png)

<br>

***

<br>
<br>

## Relationship between Insured Rate and Primary Care Access: Poisson Regression

### Cleaning Data

  Firstly we need to clean our data sets by removing all missing values. We will check how many observations we end up eliminating to be sure that this removal will not impact our analysis significantly. Table 4 reports the number of observations before and after cleaning for each year as well as the percentage removed. Since only a small fraction (at most 0.79%) were removed for any given year we accept that the effect of these removals will be negligible. We will also split each data set in half so we will have one half for fitting our model and one half for testing.

```{r, include=F, eval=F}

library(Hmisc)
BRFSS2015full <- sasxport.get("LLCP2015.XPT")
BRFSS2014full <- sasxport.get("LLCP2014.XPT")
BRFSS2013full <- sasxport.get("LLCP2013.XPT")
BRFSS2012full <- sasxport.get("LLCP2012.XPT")
BRFSS2011full <- sasxport.get("LLCP2011.XPT")

t15.data <- BRFSS2015full[,c("hlthpln1", "persdoc2", "x.llcpwt", "x.state")]
t14.data <- BRFSS2014full[,c("hlthpln1", "persdoc2", "x.llcpwt", "x.state")]
t13.data <- BRFSS2013full[,c("hlthpln1", "persdoc2", "x.llcpwt", "x.state")]
t12.data <- BRFSS2012full[,c("hlthpln1", "persdoc2", "x.llcpwt", "x.state")]
t11.data <- BRFSS2011full[,c("hlthpln1", "persdoc2", "x.llcpwt", "x.state")]

rm(BRFSS2015full, BRFSS2014full, BRFSS2013full, BRFSS2012full, BRFSS2011full)


## count observations before cleaning
n <- c(nrow(t11.data),
       nrow(t12.data),
       nrow(t13.data),
       nrow(t14.data),
       nrow(t15.data))


## Remove missing values, refusals to respond, and thuse who were unsure
cleaner <- function(x){
  
      df <- x
      
      for(i in 1:4){
            df <- df[!is.na(df[,i]),] 
      }
      
      for(i in 1:2){
           df <- df[df[,i] != 7 & df[,i] != 9,] 
      }

      
      df
}

t11.data <- cleaner(t11.data)
t12.data <- cleaner(t12.data)
t13.data <- cleaner(t13.data)
t14.data <- cleaner(t14.data)
t15.data <- cleaner(t15.data)

## Count observations after cleaning
nc <- c(nrow(t11.data),
        nrow(t12.data),
        nrow(t13.data),
        nrow(t14.data),
        nrow(t15.data))



removed.vals <- matrix(c(n, nc, (n-nc), ((n-nc)/n)*100), nrow = 5, ncol = 4,
                       dimnames = list(c("2011", "2012", "2013", "2014", "2015"),
                                       c("Total Before Cleaning", "Total After Cleaning", "Number Removed", "Percentage Removed"))
                       )
write.csv(removed.vals, "data/removedvaluestable.csv")

## splitting data sets

t11.data[,"index"] <- 1:nrow(t11.data)
sf <-            sample(nrow(t11.data), size = ceiling(nrow(t11.data)/2))
st <-         setdiff(1:nrow(t11.data), sf)
t11.data.fit <-              t11.data[sf, ]
t11.data.test <-             t11.data[st, ]

t12.data[,"index"] <- 1:nrow(t12.data)
sf <-            sample(nrow(t12.data), size = ceiling(nrow(t12.data)/2))
st <-         setdiff(1:nrow(t12.data), sf)
t12.data.fit <-              t12.data[sf, ]
t12.data.test <-             t12.data[st, ]

t13.data[,"index"] <- 1:nrow(t13.data)
sf <-            sample(nrow(t13.data), size = ceiling(nrow(t12.data)/2))
st <-         setdiff(1:nrow(t13.data), sf)
t13.data.fit <-              t13.data[sf, ]
t13.data.test <-             t13.data[st, ]

t14.data[,"index"] <- 1:nrow(t14.data)
sf <-            sample(nrow(t14.data), size = ceiling(nrow(t12.data)/2))
st <-         setdiff(1:nrow(t14.data), sf)
t14.data.fit <-              t14.data[sf, ]
t14.data.test <-             t14.data[st, ]

t15.data[,"index"] <- 1:nrow(t15.data)
sf <-            sample(nrow(t15.data), size = ceiling(nrow(t12.data)/2))
st <-         setdiff(1:nrow(t15.data), sf)
t15.data.fit <-              t15.data[sf, ]
t15.data.test <-             t15.data[st, ]


write.csv(t11.data[,1:4], 'data/Cleaned 2011 BRFSS Data.csv')
write.csv(t12.data[,1:4], 'data/Cleaned 2012 BRFSS Data.csv')
write.csv(t13.data[,1:4], 'data/Cleaned 2013 BRFSS Data.csv')
write.csv(t14.data[,1:4], 'data/Cleaned 2014 BRFSS Data.csv')
write.csv(t15.data[,1:4], 'data/Cleaned 2015 BRFSS Data.csv')

write.csv(t11.data.fit[,1:4], 'data/Cleaned 2011 BRFSS Data for Fitting.csv')
write.csv(t12.data.fit[,1:4], 'data/Cleaned 2012 BRFSS Data for Fitting.csv')
write.csv(t13.data.fit[,1:4], 'data/Cleaned 2013 BRFSS Data for Fitting.csv')
write.csv(t14.data.fit[,1:4], 'data/Cleaned 2014 BRFSS Data for Fitting.csv')
write.csv(t15.data.fit[,1:4], 'data/Cleaned 2015 BRFSS Data for Fitting.csv')

write.csv(t11.data.test[,1:4], 'data/Cleaned 2011 BRFSS Data for Testing.csv')
write.csv(t12.data.test[,1:4], 'data/Cleaned 2012 BRFSS Data for Testing.csv')
write.csv(t13.data.test[,1:4], 'data/Cleaned 2013 BRFSS Data for Testing.csv')
write.csv(t14.data.test[,1:4], 'data/Cleaned 2014 BRFSS Data for Testing.csv')
write.csv(t15.data.test[,1:4], 'data/Cleaned 2015 BRFSS Data for Testing.csv')

t11.data <- data.frame(read.csv("data/Cleaned 2011 BRFSS Data for Fitting.csv"))[,2:5]
t12.data <- data.frame(read.csv("data/Cleaned 2012 BRFSS Data for Fitting.csv"))[,2:5]
t13.data <- data.frame(read.csv("data/Cleaned 2013 BRFSS Data for Fitting.csv"))[,2:5]
t14.data <- data.frame(read.csv("data/Cleaned 2014 BRFSS Data for Fitting.csv"))[,2:5]
t15.data <- data.frame(read.csv("data/Cleaned 2015 BRFSS Data for Fitting.csv"))[,2:5]

```

***

```{r, include=F}

removed.vals <- read.csv("data/removedvaluestable.csv")

```

```{r, echo=F, results="asis"}

colnames(removed.vals) <- c("Year", "Total Before Cleaning", "Total After Cleaning", "Number Removed", "Percentage Removed")

pandoc.table(removed.vals,
             caption = "**Table 4:** Number of missing values removed from data sets.",
             split.table = Inf)

```

<br>

***

<br>
<br>
### Computed Weighted Counts

  We are interested in how the percentage of individuals with a personal doctor in a state is related to the percentage of people with insurance. Viewing percentage of people with a personal doctor as a rate (a per capita rate) we can use Poisson regression to regress this rate on the pecentage of individuals with insurance. We will use each individual state/territory included in the BRFSS as an observation. In order to do this we need to get the counts of individuals with a personal doctor and the counts of individuals with insurance for each state/territory. When doing this though we need to make use of the recomended weights in the BRFSS.
  
  For each observation (state/territory) we will have three values:

+ Weighted counts (rounded to nearest integer) of respondents with a personal doctor in that state
+ Weighted counts (rounded to nearest integer) of respondents with insurance in that state
+ Total number of respondents from that state (used as the offset in the regression model)

```{r, include=F, eval=F}

counter <- function(x){
  
  out <- matrix(data = NA, 
                nrow = length(unique(x$x.state)),
                ncol = 4)
  colnames(out) <- c("Personal Doctor Count", "Insurance Count", "Total Respondents", "Medicaid Expansion")
  
  c <- 0
  for(i in unique(x$x.state)){
    
    c <- c + 1
    wsum <- sum(x$x.llcpwt[x$x.state == i])
    n <- length(x$x.llcpwt[x$x.state == i])
    wf <- n/wsum
    
    countpd <- sum(x$x.llcpwt[x$x.state == i & x$persdoc2 == 1]) + sum(x$x.llcpwt[x$x.state == i & x$persdoc2 == 2])
    countpd <- round(countpd*wf, digits = 0)
    
    countin <- sum(x$x.llcpwt[x$x.state == i & x$hlthpln1 == 1])
    countin <- round(countin*wf, digits = 0)
    
    out[c,1] <- countpd
    out[c,2] <- countin
    out[c,3] <- n
    
  }
  
  
  
  rownames(out) <- c(state.abb[1:8],
                     "DC",
                     state.abb[9:50],
                     "GU", "PR")
  
  states <- as.character(row(out, as.factor = T)[,1])
  states <-  setdiff(states, c("AK", "AR", "AZ", 
                               "IA", "IN", "MI", 
                               "NH", "PA", "WI")
                     )
  
  nomed <- c("AL", "FL", "GA", "ID", 
             "KS", "LA", "ME", "MS",
             "MT", "MO", "NE", "NC", 
             "OK", "SC", "SD", "TN",
             "TX", "UT", "VA", "WY")
  
  med <- setdiff(states, nomed)
  
  out[c("AK", "AR", "AZ", 
        "IA", "IN", "MI", 
        "NH", "PA", "WI"), 4] <- 100
  out[nomed, 4] <- 0
  out[med, 4] <- 1
  
  
  out
}

t11.counts <- counter(t11.data)
t12.counts <- counter(t12.data)
t13.counts <- counter(t13.data)
t14.counts <- counter(t14.data)
t15.counts <- counter(t15.data)
AY.counts <- t15.counts + t12.counts + t13.counts + t14.counts + t15.counts
AY.counts[,4] <- AY.counts[,4]/5

write.csv(t11.counts, "data/2011 counts.csv")
write.csv(t12.counts, "data/2012 counts.csv")
write.csv(t13.counts, "data/2013 counts.csv")
write.csv(t14.counts, "data/2014 counts.csv")
write.csv(t15.counts, "data/2015 counts.csv")
write.csv(AY.counts, "data/All Year counts.csv")

```

```{r, include=F}

t11.counts <- read.csv("data/2011 counts.csv")
rownames(t11.counts) <- t11.counts[,1]
t11.counts <- t11.counts[,2:5]

t12.counts <- read.csv("data/2012 counts.csv")
rownames(t12.counts) <- t12.counts[,1]
t12.counts <- t12.counts[,2:5]

t13.counts <- read.csv("data/2013 counts.csv")
rownames(t13.counts) <- t13.counts[,1]
t13.counts <- t13.counts[,2:5]

t14.counts <- read.csv("data/2014 counts.csv")
rownames(t14.counts) <- t14.counts[,1]
t14.counts <- t14.counts[,2:5]

t15.counts <- read.csv("data/2015 counts.csv")
rownames(t15.counts) <- t15.counts[,1]
t15.counts <- t15.counts[,2:5]

AY.counts <- read.csv("data/All Year counts.csv")
rownames(AY.counts) <- AY.counts[,1]
AY.counts <- AY.counts[,2:5]

```

For instance, the observation for the state of Maine for 2011 would look as follows

***

```{r, echo=F, results="asis"}

x <- t11.counts["ME",]
colnames(x) <- c("Personal Doctor Count", "Insurance Count", "Total Respondents", "Medicaid Expansion")

pandoc.table(x[1:3],
             caption = "2011 observation for state of Maine",
             split.table = Inf)

```

***
<br>

```{r, include=F}

## Standardizing counts by total number of respondents

t11.std <- data.frame(t11.counts)
t11.std[,1] <- round(100*t11.std[,1]/t11.std[,3], digits = 5)
t11.std[,2] <- round(100*t11.std[,2]/t11.std[,3], digits = 5)

t12.std <- data.frame(t12.counts)
t12.std[,1] <- round(100*t12.std[,1]/t12.std[,3], digits = 5)
t12.std[,2] <- round(100*t12.std[,2]/t12.std[,3], digits = 5) 

t13.std <- data.frame(t13.counts)
t13.std[,1] <- round(100*t13.std[,1]/t13.std[,3], digits = 5)
t13.std[,2] <- round(100*t13.std[,2]/t13.std[,3], digits = 5) 

t14.std <- data.frame(t14.counts)
t14.std[,1] <- round(100*t14.std[,1]/t14.std[,3], digits = 5)
t14.std[,2] <- round(100*t14.std[,2]/t14.std[,3], digits = 5) 

t15.std <- data.frame(t15.counts)
t15.std[,1] <- round(100*t15.std[,1]/t15.std[,3], digits = 5)
t15.std[,2] <- round(100*t15.std[,2]/t15.std[,3], digits = 5)

AY.std <- data.frame(AY.counts)
AY.std[,1] <- round(100*AY.std[,1]/AY.std[,3], digits = 0)
AY.std[,2] <- round(100*AY.std[,2]/AY.std[,3], digits = 0) 

```

We will standardize the values to counts per 100 respondents so the Maine 2011 observation will become:

***

```{r, echo=F, results="asis"}

x[1] <- round(100*x[1]/x[3], digits = 5)
x[2] <- round(100*x[2]/x[3], digits = 5)

pandoc.table(x[1:3],
             caption = "Standardized 2011 observation for state of Maine",
             split.table = Inf)

```

***
<br>

Since we are including all 50 states, the Distric of Colombia, Puerto Rico, and Guam we have 53 observations for each year.

  Figure 3 below plots the standardized personal doctor counts against the standardized insurance counts for each state. The figure gives plots for each year, all years combined, the five year averages for each state, and the difference between 2015 and 2011. From all these plots it is clear that there is a positive correlation between the standardized counts of individuals with a personal doctor and the the standardized insured rate. Notice that the spread of points for the five year average is much less than that for each individual year. This makes theoretical sense, since we expect variance to be reduced when we take an average.
  
***
  
```{r, include=F}

png("plots/counts_vs_insur.png",
    height = 768, width = 744)

par(mar = c(5.1, 4.1, 2.1, 2.1), oma = c(0,0,3,0))
layout(matrix(c(1,1,2,2,3,3,4,4,5,5,6,6,7,7,0,8,8,8), 3, 6, byrow = TRUE))


plot(t11.std$Insurance.Count, t11.std$Personal.Doctor.Count,
     ylim = c(60, 90),
     xlim = c(65, 100),
     main = "2011",
     ylab = "Standardized Personal Doctor Counts",
     xlab = "Standardized Insurance Counts",  
     cex.lab = 1.2, cex.main = 1.2, pch = 20, col = "darkmagenta")

plot(t12.std$Insurance.Count, t12.std$Personal.Doctor.Count,
     ylim = c(60, 90),
     xlim = c(65, 100),
     main = "2012",
     ylab = "Standardized Personal Doctor Counts",
     xlab = "Standardized Insurance Counts",
     cex.lab = 1, cex.main = 1.2, pch = 20, col = "blue")

plot(t13.std$Insurance.Count, t13.std$Personal.Doctor.Count,
     ylim = c(60, 90),
     xlim = c(65, 100),
     main = "2013",
     ylab = "Standardized Personal Doctor Counts",
     xlab = "Standardized Insurance Counts",
     cex.lab = 1.2, cex.main = 1.2, pch = 20, col = "green")

plot(t14.std$Insurance.Count, t14.std$Personal.Doctor.Count,
     ylim = c(60, 90),
     xlim = c(65, 100),
     main = "2014",
     ylab = "Standardized Personal Doctor Counts",
     xlab = "Standardized Insurance Counts",
     cex.lab = 1.2, cex.main = 1.2, pch = 20, col = "orange")

plot(t15.std$Insurance.Count, t15.std$Personal.Doctor.Count,
     ylim = c(60, 90),
     xlim = c(65, 100),
     main = "2015",
     ylab = "Standardized Personal Doctor Counts",
     xlab = "Standardized Insurance Counts",
     cex.lab = 1.2, cex.main = 1.2, pch = 20, col = "red")

plot(t11.std$Insurance.Count, t11.std$Personal.Doctor.Count,
     ylim = c(60, 90),
     xlim = c(65, 100),
     main = "2011 to 2015",
     ylab = "Standardized Personal Doctor Counts",
     xlab = "Standardized Insurance Counts",
     cex.lab = 1.2, cex.main = 1.2, pch = 20, col = "darkmagenta")

points(t12.std$Insurance.Count, t12.std$Personal.Doctor.Count,
       pch = 20, col = "blue")

points(t13.std$Insurance.Count, t13.std$Personal.Doctor.Count,
       pch = 20, col = "green")


points(t14.std$Insurance.Count, t14.std$Personal.Doctor.Count,
       pch = 20, col = "orange")

points(t15.std$Insurance.Count, t15.std$Personal.Doctor.Count,
       pch = 20, col = "red")

plot(AY.std$Insurance.Count, AY.std$Personal.Doctor.Count,
     ylim = c(60, 90),
     xlim = c(65, 100),
     main = "Five Year Average",
     ylab = "Standardized Personal Doctor Counts",
     xlab = "Standardized Insurance Counts",
     cex.lab = 1.2, cex.main = 1.2, pch = 20)


plot(t15.std$Insurance.Count - t11.std$Insurance.Count, 
     t15.std$Personal.Doctor.Count - t11.std$Personal.Doctor.Count,
     ylim = c(-25, 20),
     xlim = c(-15, 20),
     main = "Change between 2011 and 2015",
     ylab = "Difference in Personal Doctor Counts",
     xlab = "Difference in Insured Counts",
     cex.lab = 1.2, cex.main = 1.2, pch = 20)

mtext('Personal Doctor Counts v.s. Insurance Counts', outer = TRUE, font = 2, padj = -1, cex = 1.2)

dev.off()

```

![**Figure 3:** The plot above shows the standardized personal doctor counts plotted against the standardized insurance counts. The points in blue correspond to data from 2011, cyan from 2012, green from 2013, orange from 2014, and red from 2015. The first five plots show each of these years individually while the sixth plot shows all the years combined. From the 6th plot it appears that there is a general shift upwards to the left which would correspond with increaseing insured rates and increasing counts of individuals with a personal doctor. The 7th plot shows the 2011 to 2015 average for all states. Note that the spread of the data is much decreased in the 7th plot. The 8th plot shows the difference in personal doctor counts and insurance counts between 2015 and 2011 for each state.](plots/counts_vs_insur.png)

***
<br>
<br>



### Model Fitting and Diagnostics

  To fit our Poisson models, we will use the built in R function for fitting generlized linear models ("glm()"). We will fit one model for each year and then one model for all years combined (five year averages). The model for the five year averages will still be fit using only 53 observations because each state still only counts for 1 observation. We do this because we cannot count different years for the same state as different observations because we cannot reasonably assume that these observations would be independent. Figure 4 shows the fitted log-linear models over scatterplots of the data.
  
```{r, include=F}

t11.glm <- glm(Personal.Doctor.Count ~ Insurance.Count, family = poisson, data = t11.std)
t12.glm <- glm(Personal.Doctor.Count ~ Insurance.Count, family = poisson, data = t12.std)
t13.glm <- glm(Personal.Doctor.Count ~ Insurance.Count, family = poisson, data = t13.std)
t14.glm <- glm(Personal.Doctor.Count ~ Insurance.Count, family = poisson, data = t14.std)
t15.glm <- glm(Personal.Doctor.Count ~ Insurance.Count, family = poisson, data = t15.std)
AY.glm <- glm(Personal.Doctor.Count ~ Insurance.Count, family = poisson, data = AY.std)

```

```{r, include=F}

library(AER)
dispersiontest(t11.glm, alternative = "two.sided")
dispersiontest(t12.glm, alternative = "two.sided")
dispersiontest(t13.glm, alternative = "two.sided")
dispersiontest(t14.glm, alternative = "two.sided")
dispersiontest(t15.glm, alternative = "two.sided")
dispersiontest(AY.glm, alternative = "two.sided")

```

```{r, include=F}

t11.glm <- glm(Personal.Doctor.Count ~ Insurance.Count, family = quasipoisson, data = t11.std)
t12.glm <- glm(Personal.Doctor.Count ~ Insurance.Count, family = quasipoisson, data = t12.std)
t13.glm <- glm(Personal.Doctor.Count ~ Insurance.Count, family = quasipoisson, data = t13.std)
t14.glm <- glm(Personal.Doctor.Count ~ Insurance.Count, family = quasipoisson, data = t14.std)
t15.glm <- glm(Personal.Doctor.Count ~ Insurance.Count, family = quasipoisson, data = t15.std)
AY.glm <- glm(Personal.Doctor.Count ~ Insurance.Count, family = quasipoisson, data = AY.std)

sumt11 <- summary(t11.glm)
sumt12 <- summary(t12.glm)
sumt13 <- summary(t13.glm)
sumt14 <- summary(t14.glm)
sumt15 <- summary(t15.glm)
sumAY <- summary(AY.glm)

```

***
  
```{r, include = F}


png("plots/models.png",
    height = 620, width = 960)

par(mfrow = c(2,3), mar = c(5.1, 4.1, 2.1, 2.1), oma = c(0,0,3,0))
#layout(matrix(c(1,1,2,2,3,3,4,4,5,5,6,6,7,7,0,8,8,8), 3, 6, byrow = TRUE))


plot(t11.std$Insurance.Count, t11.std$Personal.Doctor.Count,
     ylim = c(60, 90),
     xlim = c(65, 100),
     main = "2011",
     ylab = "Standardized Personal Doctor Counts",
     xlab = "Standardized Insurance Counts",
     cex.lab = 1.2, cex.main = 1.2, pch = 20, col = "darkmagenta")
curve(exp(sumt11$coefficients[1,1] + sumt11$coefficients[2,1]*x), n = 1000, from = 60, to = 105, add = T)

plot(t12.std$Insurance.Count, t12.std$Personal.Doctor.Count,
     ylim = c(60, 90),
     xlim = c(65, 100),
     main = "2012",
     ylab = "Standardized Personal Doctor Counts",
     xlab = "Standardized Insurance Counts",
     cex.lab = 1, cex.main = 1.2, pch = 20, col = "blue")
curve(exp(sumt12$coefficients[1,1] + sumt12$coefficients[2,1]*x), n = 1000, from = 60, to = 105, add = T)

plot(t13.std$Insurance.Count, t13.std$Personal.Doctor.Count,
     ylim = c(60, 90),
     xlim = c(65, 100),
     main = "2013",
     ylab = "Standardized Personal Doctor Counts",
     xlab = "Standardized Insurance Counts",
     cex.lab = 1.2, cex.main = 1.2, pch = 20, col = "green")
curve(exp(sumt13$coefficients[1,1] + sumt13$coefficients[2,1]*x), n = 1000, from = 60, to = 105, add = T)

plot(t14.std$Insurance.Count, t14.std$Personal.Doctor.Count,
     ylim = c(60, 90),
     xlim = c(65, 100),
     main = "2014",
     ylab = "Standardized Personal Doctor Counts",
     xlab = "Standardized Insurance Counts",
     cex.lab = 1.2, cex.main = 1.2, pch = 20, col = "orange")
curve(exp(sumt14$coefficients[1,1] + sumt14$coefficients[2,1]*x), n = 1000, from = 60, to = 105, add = T)

plot(t15.std$Insurance.Count, t15.std$Personal.Doctor.Count,
     ylim = c(60, 90),
     xlim = c(65, 100),
     main = "2015",
     ylab = "Standardized Personal Doctor Counts",
     xlab = "Standardized Insurance Counts",
     cex.lab = 1.2, cex.main = 1.2, pch = 20, col = "red")
curve(exp(sumt15$coefficients[1,1] + sumt15$coefficients[2,1]*x), n = 1000, from = 60, to = 105, add = T)

plot(AY.std$Insurance.Count, AY.std$Personal.Doctor.Count,
     ylim = c(60, 90),
     xlim = c(65, 100),
     main = "Five Year Average",
     ylab = "Standardized Personal Doctor Counts",
     xlab = "Standardized Insurance Counts",
     cex.lab = 1.2, cex.main = 1.2, pch = 20)
curve(exp(sumAY$coefficients[1,1] + sumAY$coefficients[2,1]*x), n = 1000, from = 60, to = 105, add = T)

mtext('Fitted Models and Observed Data', outer = TRUE, font = 2, padj = -1, cex = 1.2)

dev.off()


```

![**Figure 4:** Log-linear models of standardized personal doctor counts regressed onto standardized insured rates.](plots/models.png)

***
<br>
  
  After fitting our models we used the dispersion test ("dispersiontest()") from the Applied Econometrics with R ("AER") package to test if our data was over- or under-dispersed for a Poisson distribution. We found that our data for each model was significantly underdispersed. To correct for this, we refit the model using the "quasipoisson" family option which uses a Poisson distribution with an estimated dispersion parameter. This does not effect the estimates of the regression parameters, but it does effect the estimated standard errors of said parameters. In our case, since our data were under-dispersed, our estimated standard errors decreased. Table 5 below reports the estimated model parameters, their standard errors, and their p-values.

***

```{r, echo=F, results="asis"}

x <- matrix(c(sumt11$coefficients[1,1], sumt11$coefficients[1,2], sumt11$coefficients[1,4],
              sumt11$coefficients[2,1], sumt11$coefficients[2,2], sumt11$coefficients[2,4],
              sumt12$coefficients[1,1], sumt12$coefficients[1,2], sumt12$coefficients[1,4],
              sumt12$coefficients[2,1], sumt12$coefficients[2,2], sumt12$coefficients[2,4],
              sumt13$coefficients[1,1], sumt13$coefficients[1,2], sumt13$coefficients[1,4],
              sumt13$coefficients[2,1], sumt13$coefficients[2,2], sumt13$coefficients[2,4],
              sumt14$coefficients[1,1], sumt14$coefficients[1,2], sumt14$coefficients[1,4],
              sumt14$coefficients[2,1], sumt14$coefficients[2,2], sumt14$coefficients[2,4],
              sumt15$coefficients[1,1], sumt15$coefficients[1,2], sumt15$coefficients[1,4],
              sumt15$coefficients[2,1], sumt15$coefficients[2,2], sumt15$coefficients[2,4],
              sumAY$coefficients[1,1], sumAY$coefficients[1,2], sumAY$coefficients[1,4],
              sumAY$coefficients[2,1], sumAY$coefficients[2,2], sumAY$coefficients[2,4]
              ), nrow = 12, ncol = 3, byrow = T)

x <- data.frame(x)

x <- cbind(rep(c("Intercept", "Slope"), 6), x)

colnames(x) <- c("", "Estimate", "Standard Error", "P-value")
rownames(x) <- c("2011", "", "2012", " ", "2013", "   ", "2014", "     ", "2015", "      ", "Five Year Average", "       ")

pandoc.table(x,
             caption = "**Table 5:** Estimated model parameters, standard errors, and p-values for each fitted model.",
             split.table = Inf)
```
  
<br>

***

<br>

#### Residual Analysis

  Figure 4 below shows the residuals plotted agains the fitted values for each model. There does not appear to be any pattern to the residual scattering for any of the models.
  
***
  
```{r, include=F}

png("plots/Residual_Plots.png",
     height = 600, width = 900)

par(mfrow=c(2,3), mar = c(5.1, 4.1, 7.1, 2.1))

plot(t11.glm$fitted.values, t11.std$Personal.Doctor.Count - t11.glm$fitted.values,
     ylim = c(-15, 15),
     xlim = c(65, 90),
     main = "2011",
     ylab = "Residuals",
     xlab = "Fitted Values",
     cex.lab = 1.1, cex.main = 1.2 )
abline(h=0)

plot(t12.glm$fitted.values,  t12.std$Personal.Doctor.Count - t12.glm$fitted.values,
     ylim = c(-15, 15),
     xlim = c(65, 90),
     main = "2012",
     ylab = "Residuals",
     xlab = "Fitted Values",
     cex.lab = 1.1, cex.main = 1.2 )
abline(h=0)

plot(t13.glm$fitted.values, t13.std$Personal.Doctor.Count - t13.glm$fitted.values,
     ylim = c(-15, 15),
     xlim = c(65, 90),
     main = "2013",
     ylab = "Residuals",
     xlab = "Fitted Values",
     cex.lab = 1.1, cex.main = 1.2 )
abline(h=0)

plot(t14.glm$fitted.values,  t14.std$Personal.Doctor.Count - t14.glm$fitted.values,
     ylim =c(-15, 15),
     xlim = c(65, 90),
     main = "2014",
     ylab = "Residuals",
     xlab = "Fitted Values",
     cex.lab = 1.1, cex.main = 1.2 )
abline(h=0)

plot(t15.glm$fitted.values,  t15.std$Personal.Doctor.Count - t15.glm$fitted.values,
     ylim = c(-15, 15),
     xlim = c(65, 90),
     main = "2015",
     ylab = "Residuals",
     xlab = "Fitted Values",
     cex.lab = 1.1, cex.main = 1.2 )
abline(h=0)

plot(AY.glm$fitted.values,  AY.std$Personal.Doctor.Count - AY.glm$fitted.values,
     ylim = c(-10, 10),
     xlim = c(70, 85),
     main = "Five Year Average",
     ylab = "Residuals",
     xlab = "Fitted Values",
     cex.lab = 1.1, cex.main = 1.2 )
abline(h=0)

mtext('Residual Plots', outer = TRUE, font = 2, padj = 1.5, cex = 1.2)

dev.off()

``` 
  
![**Figure 4:** The plots above show the residuals plotted against the fitted values for each model.](plots/Residual_Plots.png)  

***
<br>
<br>

#### Global Fit Tests
<br>
  For global fit tests we are testing the null hypothesis that the model fits the data to the alternative hypothesis that the model does not fit the data and there is significant lack of fit. We performed two global fit tests for each model, the Pearson test and the likelihood ratio test. All six of our models passed both tests, indicating that there is no significant lack-of-fit.

##### Pearson Goodness-of-Fit Test

  The test-statistic for the Pearson test is:
  
  $$X^2 = \sum_{i = 1}^n {\frac{(y_i - \widehat{\mu_i})^2}{\widehat{\mu_i}}} \sim \chi_{n - p}^ 2 \\ n = \text{number of observations} \\ p = \text{number of model parameters} $$
  
<br>

  For all of our model, the number of observations in the data set is 53 and the number of parameters is 2 (slope and intercept coefficients) so the degrees of freedom are 51. We used the following R function to calculate the test-statistic and corresponding p-value for each distribution.

***

```{r}
#Function takes fitted values and observed values as arguments

Pearson.Global.Fit <- function(fitval, obsval, df = 51){
  
  TS <- sum( (obsval - fitval)^2 / fitval ) 
  p <- pchisq(TS, df, lower.tail = FALSE)
  
  out <- data.frame(c(TS, p))
  out <- t(out)
  colnames(out) <- c("Test-Statistic", "P-value")
  
  out
}
```

***

<br>

  Table 6 below reports the test-statistics and corresponding p-values for each model. The p-values are all approximately 1 indicating that we should accept the null hypothesis that the models fit the data.

***
  
```{r, echo=F, results="asis"}

x <- rbind(Pearson.Global.Fit(t11.glm$fitted.values, t11.std$Personal.Doctor.Count),
           Pearson.Global.Fit(t12.glm$fitted.values, t12.std$Personal.Doctor.Count),
           Pearson.Global.Fit(t13.glm$fitted.values, t13.std$Personal.Doctor.Count),
           Pearson.Global.Fit(t14.glm$fitted.values, t14.std$Personal.Doctor.Count),
           Pearson.Global.Fit(t15.glm$fitted.values, t15.std$Personal.Doctor.Count),
           Pearson.Global.Fit(AY.glm$fitted.values, AY.std$Personal.Doctor.Count)
           )
rownames(x) <- c("2011", "2012", "2013", "2014", "2015", "Five Year Average")

pandoc.table(x,
             caption = "**Table 6:** Pearson goodness-of-fit test-statistics and p-values for each model",
             split.table = Inf)

```

<br>

***
<br>
<br>

##### Likelihood Ratio Goodness-of-Fit Test

  The test-statistic for the likelihood ratio test is:

$$G^2 = 2 \sum_{i = 1}^n {y_i\ln{\frac{y_i}{\widehat{\mu_i}}}} \sim \chi_{n - p}^ 2 \\ n = \text{number of observations} \\ p = \text{number of model parameters}$$

<br>

  Again all our models were fitted using data sets of 53 observations and all of our models have 2 parameters so our degrees of freedom are 51. We used the following R function to calculate the likelihood ratio test-statistic and corresponding p-value for each model.
  
***

```{r}
#Function takes fitted values and observed values as arguments

LR.Global.Fit <- function(fitval, obsval, df = 51){
  
  TS <- 2*abs(sum( (obsval) * log( (obsval)/(fitval) ) ) )
  p <- pchisq(TS, df, lower.tail = FALSE)
  
  out <- data.frame(c(TS, p))
  out <- t(out)
  colnames(out) <- c("Test-Statistic", "P-value")
  
  out
}
```

***

<br>

  Table 7 reports the calculated likelihood ratio test-statistics and corresponding p-values for each model. The p-values of virtually 1 indicate that, as with the Pearson test, the likelihood ratio test found no evidence of lack of fit for any of our models. Thus, we accept the null hypothesis that our models fit the data.
  
***
  
```{r, echo=F, results="asis"}

x <- rbind(LR.Global.Fit(t11.glm$fitted.values, t11.std$Personal.Doctor.Count),
           LR.Global.Fit(t12.glm$fitted.values, t12.std$Personal.Doctor.Count),
           LR.Global.Fit(t13.glm$fitted.values, t13.std$Personal.Doctor.Count),
           LR.Global.Fit(t14.glm$fitted.values, t14.std$Personal.Doctor.Count),
           LR.Global.Fit(t15.glm$fitted.values, t15.std$Personal.Doctor.Count),
           LR.Global.Fit(AY.glm$fitted.values, AY.std$Personal.Doctor.Count)
           )
rownames(x) <- c("2011", "2012", "2013", "2014", "2015", "Five Year Average")

pandoc.table(x,
             caption = "**Table 7:** Likelihood ratio goodness-of-fit test-statistics and p-values for each model",
             split.table = Inf)

```

<br>

***
<br>
<br>

#### Comparative Fit

  From looking at the residual plots and the results of the global fit tests we have no reason to think that our models poorly fit the data. Now we want to see if they give us better fit than just the null model (a horizontal line at the global mean of the data set). To do this we will test the difference between deviance of the null model and the fitted model. The null hypothesis of this test is that the fitted model gives no better fit than the null model, the alternative is that it does give significantly better fit. The test statistic is the difference between the deviance of the null model and the deviance of the fitted model. The smaller the difference the less likely it is that the fitted model gives better fit than the null model. The test statistic has a chi-squared distribution with degrees of freedom equal to the difference between the number of parameters in the null model and the fitted model. So for us, the degrees of freedom will equal 1.
  
  $$ TS = \text{Deviance}_{null} - \text{Deviance}_{fitted} \sim{\chi_1^2} $$

  We can use the "summary()" function to find the deviance of each of our fitted models and their corresponding null models. Table 8 below reports the test-statistics and p-values for each of our models. For the models for each year, the p-values were all less than .01. This indicates that even at a 99% percent significance level we should reject the null hypothesis that the fitted model gives no better fit than the null model and concluded that the fitted model does indeed provide better fit. However, for the model for five year averages the p-value was 0.20 indicating that we should *fail* to reject the null hypothesis and concluded that when looking at the averages over all years the fitted model does not give significantly better fit than the null model. 

  The finding that the fitted model for the five year averages does not give significantly better fit than the null model should not be troubling. If we look back at the plot of the five year averages in figure 3 we can see that the spread of the data is much less than that for any individual year. This means that each data point does not stray far from the global mean. If we recall that the null model is a horizontal line through the global mean it is now clear why the deviance between the fitted model and the null model is much less when looking at the five year average: all points lie relatively close to the global mean. This is effect occurs because taking the average over five years greatly reduces the variance of the data set.
  
```{r, echo=FALSE}

Comp.Fit.mod <- function(modelsum, df = 1){
  
  TS <- modelsum$null.deviance - modelsum$deviance
  p <- pchisq(TS, df, lower.tail = FALSE)
  
  out <- data.frame(c(TS, p))
  out <- t(out)
  colnames(out) <- c("Test-Statistic", "P-value")
  
  out
}

```

***

```{r, echo=F, results="asis"}

x <- rbind(Comp.Fit.mod(sumt11),
           Comp.Fit.mod(sumt12),
           Comp.Fit.mod(sumt13),
           Comp.Fit.mod(sumt14),
           Comp.Fit.mod(sumt15),
           Comp.Fit.mod(sumAY)
           )
rownames(x) <- c("2011", "2012", "2013", "2014", "2015", "Five Year Average")

pandoc.table(x,
             caption = "**Table 8:** Comparative fit test-statistics and p-values for each model",
             split.table = Inf)

```

<br>

***

<br>
<br>

#### Diagnostics Using Split Data Sets

  Earlier on we mentioned that we split the BRFSS data sets for each year in half so we could use half of a data set to fit a model and the other half to test the model. Now we will use those data sets to test the models. We will begin by performing the last three tests we just performed.

+ Pearson global fit test
+ Likelihood ratio global fit test
+ Deviance comparative fit test

  We will use the R function "predict()" to generate fitted values for observations in the diagnostic data sets and then use these fitted values to perform the above tests in the same manner as before. Tables 9 and 10 report the global fit statistics calculated using the test data sets. The p-values are still all approximately 1 indicating that there is still no evidence that our models fit the data poorly.
  
```{r, include=F, eval=F}

t11.data.test <- data.frame(read.csv("data/Cleaned 2011 BRFSS Data for Testing.csv"))[,2:5]
t12.data.test <- data.frame(read.csv("data/Cleaned 2012 BRFSS Data for Testing.csv"))[,2:5]
t13.data.test <- data.frame(read.csv("data/Cleaned 2013 BRFSS Data for Testing.csv"))[,2:5]
t14.data.test <- data.frame(read.csv("data/Cleaned 2014 BRFSS Data for Testing.csv"))[,2:5]
t15.data.test <- data.frame(read.csv("data/Cleaned 2015 BRFSS Data for Testing.csv"))[,2:5]

t11.counts.t <- counter(t11.data.test)
t12.counts.t <- counter(t12.data.test)
t13.counts.t <- counter(t13.data.test)
t14.counts.t <- counter(t14.data.test)
t15.counts.t <- counter(t15.data.test)
AY.counts.t <- t11.counts.t + t12.counts.t + t13.counts.t + t14.counts.t + t15.counts.t
AY.counts.t[,4] <- AY.counts.t[,4]/5

write.csv(t11.counts.t, "data/2011 test counts.csv")
write.csv(t12.counts.t, "data/2012 test counts.csv")
write.csv(t13.counts.t, "data/2013 test counts.csv")
write.csv(t14.counts.t, "data/2014 test counts.csv")
write.csv(t15.counts.t, "data/2015 test counts.csv")
write.csv(AY.counts.t, "data/All Year test counts.csv")

```

```{r, include=F}

t11.counts.t <- read.csv("data/2011 test counts.csv")
rownames(t11.counts.t) <- t11.counts.t[,1]
t11.counts.t <- t11.counts.t[,2:5]

t12.counts.t <- read.csv("data/2012 test counts.csv")
rownames(t12.counts.t) <- t12.counts.t[,1]
t12.counts.t <- t12.counts.t[,2:5]

t13.counts.t <- read.csv("data/2013 test counts.csv")
rownames(t13.counts.t) <- t13.counts.t[,1]
t13.counts.t <- t13.counts.t[,2:5]

t14.counts.t <- read.csv("data/2014 test counts.csv")
rownames(t14.counts.t) <- t14.counts.t[,1]
t14.counts.t <- t14.counts.t[,2:5]

t15.counts.t <- read.csv("data/2015 test counts.csv")
rownames(t15.counts.t) <- t15.counts.t[,1]
t15.counts.t <- t15.counts.t[,2:5]

AY.counts.t <- read.csv("data/All Year test counts.csv")
rownames(AY.counts.t) <- AY.counts.t[,1]
AY.counts.t <- AY.counts.t[,2:5]

t11.stdt <- data.frame(t11.counts.t)
t11.stdt[,1] <- round(100*t11.stdt[,1]/t11.stdt[,3], digits = 5)
t11.stdt[,2] <- round(100*t11.stdt[,2]/t11.stdt[,3], digits = 5)

t12.stdt <- data.frame(t12.counts.t)
t12.stdt[,1] <- round(100*t12.stdt[,1]/t12.stdt[,3], digits = 5)
t12.stdt[,2] <- round(100*t12.stdt[,2]/t12.stdt[,3], digits = 5) 

t13.stdt <- data.frame(t13.counts.t)
t13.stdt[,1] <- round(100*t13.stdt[,1]/t13.stdt[,3], digits = 5)
t13.stdt[,2] <- round(100*t13.stdt[,2]/t13.stdt[,3], digits = 5) 

t14.stdt <- data.frame(t14.counts.t)
t14.stdt[,1] <- round(100*t14.stdt[,1]/t14.stdt[,3], digits = 5)
t14.stdt[,2] <- round(100*t14.stdt[,2]/t14.stdt[,3], digits = 5) 

t15.stdt <- data.frame(t15.counts.t)
t15.stdt[,1] <- round(100*t15.stdt[,1]/t15.stdt[,3], digits = 5)
t15.stdt[,2] <- round(100*t15.stdt[,2]/t15.stdt[,3], digits = 5)

AY.stdt <- data.frame(AY.counts.t)
AY.stdt[,1] <- round(100*AY.stdt[,1]/AY.stdt[,3], digits = 0)
AY.stdt[,2] <- round(100*AY.stdt[,2]/AY.stdt[,3], digits = 0)

p11 <- exp(predict(t11.glm, t11.stdt))
p12 <- exp(predict(t12.glm, t12.stdt))
p13 <- exp(predict(t13.glm, t13.stdt))
p14 <- exp(predict(t14.glm, t14.stdt))
p15 <- exp(predict(t15.glm, t15.stdt))
pAY <- exp(predict(AY.glm, AY.stdt))


```

***
  
```{r, echo=F, results="asis"}

x <- rbind(Pearson.Global.Fit(p11, t11.stdt$Personal.Doctor.Count),
           Pearson.Global.Fit(p12, t12.stdt$Personal.Doctor.Count),
           Pearson.Global.Fit(p13, t13.stdt$Personal.Doctor.Count),
           Pearson.Global.Fit(p14, t14.stdt$Personal.Doctor.Count),
           Pearson.Global.Fit(p15, t15.stdt$Personal.Doctor.Count),
           Pearson.Global.Fit(pAY, AY.stdt$Personal.Doctor.Count)
           )
rownames(x) <- c("2011", "2012", "2013", "2014", "2015", "Five Year Average")

pandoc.table(x,
             caption = "**Table 9:** Pearson goodness-of-fit test-statistics and p-values for each model calculated using the testing half of the data sets.",
             split.table = Inf)

```

<br>

```{r, echo=F, results="asis"}

x <- rbind(LR.Global.Fit(p11, t11.stdt$Personal.Doctor.Count),
           LR.Global.Fit(p12, t12.stdt$Personal.Doctor.Count),
           LR.Global.Fit(p13, t13.stdt$Personal.Doctor.Count),
           LR.Global.Fit(p14, t14.stdt$Personal.Doctor.Count),
           LR.Global.Fit(p15, t15.stdt$Personal.Doctor.Count),
           LR.Global.Fit(pAY, AY.stdt$Personal.Doctor.Count)
           )
rownames(x) <- c("2011", "2012", "2013", "2014", "2015", "Five Year Average")

pandoc.table(x,
             caption = "**Table 10:** Likelihood ratio goodness-of-fit test-statistics and p-values for each model calculated using the testing half of the data sets.",
             split.table = Inf)

```

<br>

***

<br>

  Next we will measure the predictive power of our models using the concordance statistic Goodman and Kruskal's gamma. To do this we first predict the number of personal doctor counts for each observation in each testing data set using the corresponding model. Then we use the predicted number of personal doctor counts and observed number of personal doctor counts for each observation to calculate the number of concordant and discordant pairs of obervations in the data set. A concordant pair is a pair of observations where one observation has both a high predicted personal doctor count and observed personal doctor count than the other. A discordant pair is when one observation has a higher predicted personal doctor count but lower observed personal doctor count, or vice versa.
  
  The Goodman and Kruskal's gamma statistic is calculated as the difference between the number of concordant and discordant pairs divided by the total number of concordant or discordant pairs:
  
  $$\widehat{\gamma}  = \frac{C - D}{C + D}$$
  
  Gamma can range from -1 to 1, with negative values indicating more discordant than concordant pairs and positive values indicating more concordant pairs. In our case, a gamma value greater than 1 indicates a degree of predictive power, the closer to one the better. An approximate standard error for gamma is given by:

$$\widehat{SE}[\gamma] = \sqrt{\frac{n(1 - \widehat{\gamma}^2)}{C + D}} \\ \text{where} \space \space \space n = \text{total number of observations}$$

  We will use this approximate standard error to calculate approximate 95% confidence intervals for gamma. We created the R function below to calculate gamma and it's confidence interval. The confidence intervals are relatively large but none of them includes zero, indicating that our models do have some degree of predictive power.

```{r}
# Function takes observed values, fitted values, and desired alpha level as arguments

GK.gamma <- function(obs, fit, alpha = 0.05){
  
  z <- qnorm(alpha/2, lower.tail = F)
  n <- length(obs)
  data <- rbind(obs, fit)
  
  C <- 0
  D <- 0
  for(i in 1:(n-1)){
    o <- data[1,i]
    f <- data[2,i]
    for(j in (i+1):n){
      if(o < data[1,j] & f < data[2,j]){
        C <- C + 1
      }
      else if(o > data[1,j] & f > data[2,j]){
        C <- C + 1
      }
      else if(o > data[1,j] & f < data[2,j]){
        D <- D + 1
      }
      else if(o < data[1,j] & f > data[2,j]){
        D <- D + 1
      }
    }
  }
  
  gama <- (C - D) / (C + D)
  
  SE.gama <- sqrt( n*(1-gama^2)/(C+D) )
  
  G.LB <- gama - z*SE.gama
  G.UB <- gama + z*SE.gama
  
  out <- c(G.LB, gama, G.UB)
  
  out
}


```
  
  Table 11 gives the estimated gamma and 95% confidence intervals for gamma for each model.

***
  
```{r, echo=F, results="asis"}

x <- matrix(c(GK.gamma(obs = t11.stdt$Personal.Doctor.Count, fit = as.numeric(p11)),
              GK.gamma(obs = t12.stdt$Personal.Doctor.Count, fit = as.numeric(p12)),
              GK.gamma(obs = t13.stdt$Personal.Doctor.Count, fit = as.numeric(p13)),
              GK.gamma(obs = t14.stdt$Personal.Doctor.Count, fit = as.numeric(p14)),
              GK.gamma(obs = t15.stdt$Personal.Doctor.Count, fit = as.numeric(p15)),
              GK.gamma(obs = AY.stdt$Personal.Doctor.Count, fit = as.numeric(pAY))),
            nrow = 6, ncol = 3, byrow = T
            )
colnames(x) <- c("Lower Bound", "Point Estimate", "Upper Bound")
rownames(x) <- c("2011", "2012", "2013", "2014", "2015", "Five Year Average")

pandoc.table(x,
             caption = "**Table 11:** Estimated gamma values and 95% confidence intervals for each model.",
             split.table = Inf)

```

<br>

***

<br>
<br>

### Model Analysis

  Now that we have verified that our models satisfactorily fit the data, let us look more closely at our models. Figure 5 shows a plot including each model so they can be seen together for comparison. While the slope of each model appears to similar, as time goes on the models appear to shift to the right, indicating that the intecept changes.

***
  
```{r, include = F}


png("plots/comp_models.png",
    height = 620, width = 960)

curve(exp(sumt11$coefficients[1,1] + sumt11$coefficients[2,1]*x), n = 1000, from = 60, to = 105, 
      ylim = c(60, 90), xlim = c(65,100),
      main = "Fitted Models", 
      ylab = "Standardized Personal Doctor Count", 
      xlab = "Standardized Insured Rate",
      col = "darkmagenta")

curve(exp(sumt12$coefficients[1,1] + sumt12$coefficients[2,1]*x), n = 1000, from = 60, to = 105, 
      add = T, col = "blue")

curve(exp(sumt13$coefficients[1,1] + sumt13$coefficients[2,1]*x), n = 1000, from = 60, to = 105, 
      add = T, col = "green")

curve(exp(sumt14$coefficients[1,1] + sumt14$coefficients[2,1]*x), n = 1000, from = 60, to = 105, 
      add = T, col = "orange")

curve(exp(sumt15$coefficients[1,1] + sumt15$coefficients[2,1]*x), n = 1000, from = 60, to = 105, 
      add = T, col = "red")

curve(exp(sumAY$coefficients[1,1] + sumAY$coefficients[2,1]*x), n = 1000, from = 60, to = 105, 
      add = T)

legend(x = 65, y = 90,
       legend = c("2011", "2012", "2013", "2014", "2015", "Five Year Average"),
       col = c("darkmagenta", "blue", "green", "orange", "red"),
       lty = 1)

dev.off()


```

![**Figure 5:**  Fitted log-linear models. The slopes of each model appear relatively similar but as time goes on the models appear to shift to the right, indicating that their intercepts differ.](plots/comp_models.png) 

***
<br>

  Figure 6 shows the 95% confidence intervals for the estimated intercept and slope for each model. Even though the apparant shift seen in the log-linear models in figure 5 seems to indicate that the intercepts for the models differ, we can see from figure 6 that the confidence intervals for each intercept includes the point estimates for the intercepts of the other model. This negates the possibility that the intercepts differ significantly. Additionally, as expected from looking at figure 5, the slopes do not differ significantly either.

```{r, include = F}
# Takes summary object and desired alpha level as arguments

Param.Conf <- function(obj, alpha = 0.05){
  
  z <- qnorm(alpha/2, lower.tail = F)
  
  icpt <- obj$coefficients[1,1]
  SE.icpt <- obj$coefficients[1,2]
  LB.icpt <- icpt - z*SE.icpt
  UB.icpt <- icpt + z*SE.icpt
  
  slp <- obj$coefficients[2,1]
  SE.slp <- obj$coefficients[2,2]
  LB.slp <- slp - z*SE.slp
  UB.slp <- slp + z*SE.slp
  
  out <- c(LB.icpt, icpt, UB.icpt, NA, LB.slp, slp, UB.slp)
  
  out
}

Parameters <- matrix(c(Param.Conf(sumt11),
                       Param.Conf(sumt12),
                       Param.Conf(sumt13),
                       Param.Conf(sumt14),
                       Param.Conf(sumt15),
                       Param.Conf(sumAY)),
                     nrow = 6, ncol = 7, byrow = T)
colnames(Parameters) <- c("LB Intercept", "Intercept Estimate", "UB Intercept", "       ", "LB Slope", "Slope Estimate", "UB Slope")
rownames(Parameters) <- c("2011", "2012", "2013", "2014", "2015", "Five Year Average")

```

***

```{r, include=F}

png("plots/Param_Conf.png",
    height = 400, width = 960)

par(mfrow = c(1,2))

plot(x = c(1:6), y = Parameters[,2], 
     main = "Intercept", 
     ylab = NA,
     xlab = NA,
     xlim = c(1,6), 
     ylim = c(2.95, 3.75), 
     pch=20, col = "red",
     axes = FALSE, cex.main = 1, cex = 1, cex.lab = 1)
box()

axis(1, at = c(1:6), labels = c ("2011", "2012", "2013", "2014", "2015", "Average"), cex.axis = 1)
axis(2, at = seq(from = 2.90, to = 3.80, by = 0.1), las = 2, cex.axis = 1)

segments(c(1:6), Parameters[,1], c(1:6), Parameters[,3], 
         lwd = 1.5)

arrows(c(1:6), Parameters[,1], c(1:6), Parameters[,3], 
       lwd = 1.5, angle = 90, code = 3, length = 0.05)

##

plot(x = c(1:6), y = Parameters[,6], 
     main = "Slope", 
     ylab = NA,
     xlab = NA,
     xlim = c(1,6), 
     ylim = c(0.006, 0.016), 
     pch=20, col = "red",
     axes = FALSE, cex.main = 1, cex = 1, cex.lab = 1)
box()

axis(1, at = c(1:6), labels = c ("2011", "2012", "2013", "2014", "2015", "Average"), cex.axis = 1)
axis(2, at = seq(from = 0.006, to = 0.016, by = 0.002), las = 2, cex.axis = 1)


segments(c(1:6), Parameters[,5], c(1:6), Parameters[,7], lwd = 1.5)
arrows(c(1:6), Parameters[,5], c(1:6),Parameters[,7], lwd = 1.5, angle = 90, code = 3, length = 0.03)

mtext('95% Confidence Intervals for Model Parameters', 
      outer = T, font = 2, cex = 1.2, adj = .5, padj = 1.5)

dev.off()

```

![**Figure 6:** 95% confidence intervals for the model parameters. Since the confidence intervals for each intercept include the point estimates for every other intercept we can conclude that the intercepts do not differ significantly between models. The same is true for the slope parameters.](plots/Param_Conf.png)

***
<br>

 Table 12 reports the estimated slope and its 95% confidenct interval for each model. Recall that the repsonse variable is the number of individuals with a personal doctor per 100 respondents and the explanatory variable is the number of individuals with insurance per 100 respondents. Assuming that the BRFSS is a representative sample, we can then view the response variable as the estimated percentage of individuals with a personal doctor in a state while the explanatory variable is the estimated percentage of individuals with insurance in a state. Thus the estimated slope coefficient of 0.01104 implies that for a 1 percentage increase in individuals with insurance we should expect a $e^(0.01104) = 1.011 $ fold increase in the percentage of individuals with a personal doctor. While this may not seem like a large difference it can be quite significant. For instance, for a state the size of Maine (population ~1,292,816) an increase in insured percentage from .93 to .94 would correspond with an estimated increase of over 13,000 individuals with a personal doctor.
 
```{r, echo=F, results="asis"}

x <- Parameters[,5:7]
colnames(x) <- c("Lower Bound", "Point Estimate", "Upper Bound")

pandoc.table(x,
             caption = "**Table 12:** 95% confidence intervals for the slope parameter of each fitted model.",
             split.table = Inf)

```